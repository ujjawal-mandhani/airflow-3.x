airflow_dbt_spark:
  target: thrift
  outputs:
    livy:
      type: spark_livy
      method: livy
      host: spark-master
      port: 8998
      threads: 3
      host: namenode
      schema: default
      dbname: default
      connect_retries: 3
      connect_timeout: 60
      session_properties:
        spark.sql.warehouse.dir: hdfs://namenode:8020/user/airflow/dbt_output
    thrift-server:
      type: spark
      method: thrift        # ← tells dbt to use JDBC/Thrift
      host: spark-master    # hostname or IP of the ThriftServer container
      port: 10000           # default Thrift port (change if you used another)
      user: root            # any string is fine; usually hive
      schema: airflow_dbt       # Hive database / schema name
      threads: 4            # concurrent SQL sessions (≤ Thrift max)
      session_properties:
        spark.sql.warehouse.dir: hdfs://namenode:8020/user/airflow/dbt_output
        hoodie.metadata.enable: true
        spark.sql.catalogImplementation: hive
        hoodie.datasource.hive_sync.enable: true
        hoodie.datasource.hive_sync.metastore.uris: thrift://metastore:9083